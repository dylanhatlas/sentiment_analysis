{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chorogrid import Colorbin, Chorogrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycolors = ['#b35806', '#f1a340', '#fee0b6', '#d8daeb', '#998ec3', '#542788']\n",
    "import pandas as pd\n",
    "df = pd.read_csv('sample_state_data.csv')\n",
    "mybin = Colorbin(df['Percent_living_in_same_home_as_one_year_ago'], mycolors, proportional=True, decimals=None)\n",
    "mybin.set_decimals(1)\n",
    "mybin.recalc(fenceposts=True)\n",
    "mybin.calc_complements(0.5, '#e0e0e0', '#101010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycolors = ['#b35806', '#f1a340', '#fee0b6', '#d8daeb', '#998ec3', '#542788']\n",
    "import pandas as pd\n",
    "df = pd.read_csv('sample_state_data.csv')\n",
    "mybin = Colorbin(df['Percent_living_in_same_home_as_one_year_ago'], mycolors, proportional=True, decimals=None)\n",
    "mybin.set_decimals(1)\n",
    "mybin.recalc(fenceposts=True)\n",
    "mybin.calc_complements(0.5, '#e0e0e0', '#101010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              states: len 51: ['WY', 'WV', 'WI']...\n     colors_by_state: len 51: ['#fee0b6', '#542788', '#d8daeb']...\nfont_colors_by_state: len 51: ['#101010', '#e0e0e0', '#101010']...\n       legend_colors: len  6: ['#b35806', '#f1a340', '#fee0b6']...\n       legend_labels: len  6: ['77.7-79.8', '79.8-81.8', '81.8-83.9']...\n"
     ]
    }
   ],
   "source": [
    "states = list(df.state)\n",
    "colors_by_state = mybin.colors_out\n",
    "font_colors_by_state = mybin.complements\n",
    "legend_colors = mybin.colors_in\n",
    "legend_labels = mybin.labels\n",
    "\n",
    "for lst in ['states', 'colors_by_state', 'font_colors_by_state', 'legend_colors', 'legend_labels']:\n",
    "    obj = eval(lst)\n",
    "    print(\"{:>20}: len {:2}: {}...\".format(lst, len(obj), obj[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abbrev                                                                   AK\nfull_name                                                            Alaska\nlong_abbrev                                                           Alas.\nFIPS                                                                      2\npop                                                                  710231\nsqmi                                                                 663267\nmap_path                  m 135.58488,358.02208 -0.24846,65.59232 1.2422...\nmap_fill_default                                                          2\nmap_label_x                                                         99.7626\nmap_label_y                                                         398.173\nmap_label_text_anchor                                                middle\nmap_label_line_path                                                     NaN\naltmap_path               m 151.26632,459.09682 -0.31386,83.24785 1.5692...\nsquare_x                                                                  0\nsquare_y                                                                  0\naltsquare_x                                                               0\naltsquare_y                                                               0\nhex_x                                                                     1\nhex_y                                                                     0\nalthex_x                                                                  0\nalthex_y                                                                  0\nfourhex_x                                                                 2\nfourhex_y                                                                 1\nfourhex_contour                                              ababcdcdedefaf\nfourhex_label_offset_x                                                 0.25\nfourhex_label_offset_y                                                  0.5\nName: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "_ = pd.read_csv('usa_states.csv')\n",
    "print(_.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abbrev                       Postal abbreviation for 50 states and D.C.\nfull_name                    Full name\nlong_abbrev                  Abbreviation, based on but not identical to recommendations of Associated Press\nFIPS                         Federal Information Processing Standards\npop                          Population in 2013\nsqmi                         Area in square miles\n\nmap_path                     SVG path for geographic map\nmap_fill_default             Number, 1-4, so that no states sharing a border will have same fill\nmap_label_x                  X-coordinate for map label, e.g. state name\nmap_label_y                  Y-coordinate for map label\nmap_label_text_anchor        Text anchor (start, middle, end) for label\nmap_label_line_path          Path for line connecting state and label, if applicable\n\naltmap_path                  Alternate SVG path, without labels\n\nsquare_x                     Horizontal position of square grid\nsquare_y                     Vertical position of square grid\n\naltsquare_x                  Alternate horizontal position of square grid\naltsquare_y                  Alternate vertical position of square grid\n\nhex_x                        Horizontal position of hex grid\nhex_y                        Vertical position of hex grid\n\nfourhex_x                    Horizontal position of topmost, then leftmost, hex in four-hex multihex layout\nfourhex_y                    Vertical position of topmost, then leftmost, hex in four-hex multihex layout\nfourhex_contour              Contour of four-hex layout: a=up&right, b=down&right, c=down, d=down&left, e=up&left, f=up\nfourhex_label_offset_x       Horizontal offset of label, in terms of hex width\nfourhex_label_offset_y       Vertical offset of label, in terms of hex width\n\n"
     ]
    }
   ],
   "source": [
    "with open('usa_states_column_descriptions.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "cg = Chorogrid('usa_states.csv', states, colors_by_state)\n",
    "cg.set_title('% Living at same address as one year ago', font_dict={'font-size': 19})\n",
    "cg.set_legend(legend_colors, legend_labels, title='% of population')\n",
    "cg.draw_squares(spacing_dict={'margin_right': 150}) # otherwise legend will be cut off\n",
    "    # another strategy would be to pass a legend_offset to spacing_dict\n",
    "svg_file = 'svgmap'\n",
    "cg.done(show = True) #, save_filename=svg_file)\n",
    "# SVG(filename='svgmap.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['County and state name',\n 'fips',\n 'Median_value_of_owner-occupied_housing_units_2009-2013']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sample_county_data.csv', encoding='latin-1')\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County and state name</th>\n",
       "      <th>fips</th>\n",
       "      <th>Median_value_of_owner-occupied_housing_units_2009-2013</th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Butte County, CA</td>\n",
       "      <td>6007</td>\n",
       "      <td>225900</td>\n",
       "      <td>6007.0</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County and state name</th>\n",
       "      <th>fips</th>\n",
       "      <th>Median_value_of_owner-occupied_housing_units_2009-2013</th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Butte County, CA</td>\n",
       "      <td>6007</td>\n",
       "      <td>225900</td>\n",
       "      <td>6007.0</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join my county data\n",
    "county_data = 'co-est2015-alldata_csv_corrected.csv'\n",
    "\n",
    "df2 = pd.read_csv(county_data,encoding = \"ISO-8859-1\")\n",
    "# df2.head(20)\n",
    "list(df2)\n",
    "df2[df2['COUNTY_FIPS'] == 6007]\n",
    "\n",
    "# df2[df2['CENSUS2010POP'] == 0]\n",
    "#uncomment these two lines below\n",
    "df2 = df2[['COUNTY_FIPS','CENSUS2010POP']]\n",
    "dfj = pd.merge(df,df2, left_on = 'fips', right_on = 'COUNTY_FIPS', how='left')\n",
    "\n",
    "dfj[dfj['fips'] == 6007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>TWEET_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>TWEET_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('tweet_counties_sj.csv',encoding = \"ISO-8859-1\")\n",
    "# tweets = pd.read_csv('tweet_county_sample.csv',encoding = \"ISO-8859-1\")\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweet_counts = pd.DataFrame({'TWEET_COUNT': tweets_df.groupby([\"COUNTY_FIP\"]).size()}).reset_index()\n",
    "tweet_counts.columns = ['COUNTY_FIPS','TWEET_COUNT']\n",
    "tweet_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331    220000.0\nName: CENSUS2010POP, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfj_tweet = pd.merge(dfj,tweet_counts, left_on = 'fips', right_on = 'COUNTY_FIPS', how='left')\n",
    "dfj_tweet.head()\n",
    "dfj_tweet[dfj_tweet['fips'] == 6007]['CENSUS2010POP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj_tweet['TPP'] = (dfj_tweet['TWEET_COUNT']/dfj_tweet['CENSUS2010POP']) * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NAs with 0s, not technically correct but done here for sake of plotting\n",
    "# dfj_tweet[['TPP']] = dfj_tweet[['TPP']].fillna(value=0)\n",
    "\n",
    "#drop NAs\n",
    "# dfj_tweet[dfj_tweet['fips'] == 6007]\n",
    "# dfj_tweet = dfj_tweet.dropna(subset = ['TPP'])\n",
    "\n",
    "#replace NAs with 0s, because the tweet count for these counties is actually zero\n",
    "#change these values for the TPP column and do so in place\n",
    "dfj_tweet['TPP'] = dfj_tweet['TPP'].fillna(value=0)\n",
    "dfj_tweet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# dfj_tweet['TPP'].describe()\n",
    "\n",
    "# dfj_tweet[dfj_tweet['fips'] == 6007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0, 'size': 10000, 'end': 48793.669175834781}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.figure_factory as FF\n",
    "\n",
    "\n",
    "hist_data = dfj_tweet['TPP']\n",
    "group_labels=['Tweets']\n",
    "# fig = FF.create_distplot(hist_data,group_labels)\n",
    "# py.iplot(fig,filename='distplot with pandas')\n",
    "\n",
    "xbins=dict(start=0, size= 10000, end= np.max(hist_data)); print(xbins)\n",
    "\n",
    "tr3 = Histogram(x=hist_data, xbins=dict(start= 0, size= 50, end = max(hist_data)),\n",
    "                marker=dict(color='rgb(0,0,100)'))\n",
    "\n",
    "layout = dict(\n",
    "            title='title',\n",
    "            autosize= True,\n",
    "            bargap= 0.015,\n",
    "            height= 600,\n",
    "            width= 700,       \n",
    "            hovermode= 'x',\n",
    "            xaxis=dict(\n",
    "            autorange= True,\n",
    "            zeroline= False),\n",
    "            yaxis= dict(\n",
    "            autorange= True,\n",
    "            showticklabels= True,\n",
    "           ))\n",
    "\n",
    "ntitle = 'Histogram with histnorm=''. Each bar has the height=number of points in the corresp bin'\n",
    "layout.update(title=ntitle)\n",
    "\n",
    "fig3 = Figure(data=Data([tr3]), layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# py.plot(fig3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorlover as cl\n",
    "colors = cl.scales['5']['seq']['Reds'] #OrRd\n",
    "def rgb2hex(list_of_tuples):\n",
    "    output = []\n",
    "    for r, g, b in list_of_tuples:\n",
    "        output.append(\"#{0:02x}{1:02x}{2:02x}\".format(int(r), int(g), int(b)))\n",
    "    return output\n",
    "colors = rgb2hex(cl.to_numeric(colors))\n",
    "mycolors = colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count  label\n=====  =====\n    0  0.0-0.0\n    0  0.0-0.0\n 1880  0.0-1.4\n  633  1.4-5.3\n  630  5.3-48793.7\n"
     ]
    }
   ],
   "source": [
    "mybin = Colorbin(dfj_tweet['TPP'], mycolors, proportional=False, decimals=None)\n",
    "mybin.set_decimals(1)\n",
    "mybin.recalc(fenceposts=True)\n",
    "mybin.fencepostlabels\n",
    "mybin.fenceposts\n",
    "mybin.count_bins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from http://danieljlewis.org/files/2010/06/Jenks.pdf\n",
    "# described at http://danieljlewis.org/2010/06/07/jenks-natural-breaks-algorithm-in-python/\n",
    "\n",
    "def getJenksBreaks( dataList, numClass ):\n",
    "  dataList.sort_values(inplace=True)\n",
    "  mat1 = []\n",
    "  for i in range(0,len(dataList)+1):\n",
    "    temp = []\n",
    "    for j in range(0,numClass+1):\n",
    "      temp.append(0)\n",
    "    mat1.append(temp)\n",
    "  mat2 = []\n",
    "  for i in range(0,len(dataList)+1):\n",
    "    temp = []\n",
    "    for j in range(0,numClass+1):\n",
    "      temp.append(0)\n",
    "    mat2.append(temp)\n",
    "  for i in range(1,numClass+1):\n",
    "    mat1[1][i] = 1\n",
    "    mat2[1][i] = 0\n",
    "    for j in range(2,len(dataList)+1):\n",
    "      mat2[j][i] = float('inf')\n",
    "  v = 0.0\n",
    "  for l in range(2,len(dataList)+1):\n",
    "    s1 = 0.0\n",
    "    s2 = 0.0\n",
    "    w = 0.0\n",
    "    for m in range(1,l+1):\n",
    "      i3 = l - m + 1\n",
    "      val = float(dataList[i3-1])\n",
    "      s2 += val * val\n",
    "      s1 += val\n",
    "      w += 1\n",
    "      v = s2 - (s1 * s1) / w\n",
    "      i4 = i3 - 1\n",
    "      if i4 != 0:\n",
    "        for j in range(2,numClass+1):\n",
    "          if mat2[l][j] >= (v + mat2[i4][j - 1]):\n",
    "            mat1[l][j] = i3\n",
    "            mat2[l][j] = v + mat2[i4][j - 1]\n",
    "    mat1[l][1] = 1\n",
    "    mat2[l][1] = v\n",
    "  k = len(dataList)\n",
    "  kclass = []\n",
    "  for i in range(0,numClass+1):\n",
    "    kclass.append(0)\n",
    "  kclass[numClass] = float(dataList[len(dataList) - 1])\n",
    "  countNum = numClass\n",
    "  while countNum >= 2:#print \"rank = \" + str(mat1[k][countNum])\n",
    "    id = int((mat1[k][countNum]) - 2)\n",
    "    #print \"val = \" + str(dataList[id])\n",
    "    kclass[countNum - 1] = dataList[id]\n",
    "    k = int((mat1[k][countNum] - 1))\n",
    "    countNum -= 1\n",
    "  return kclass\n",
    "  \n",
    "def getGVF( dataList, numClass ):\n",
    "  \"\"\"\n",
    "  The Goodness of Variance Fit (GVF) is found by taking the \n",
    "  difference between the squared deviations\n",
    "  from the array mean (SDAM) and the squared deviations from the \n",
    "  class means (SDCM), and dividing by the SDAM\n",
    "  \"\"\"\n",
    "  breaks = getJenksBreaks(dataList, numClass)\n",
    "  dataList.sort_values(inplace=True)\n",
    "  listMean = sum(dataList)/len(dataList)\n",
    "  print(listMean)\n",
    "  SDAM = 0.0\n",
    "  for i in range(0,len(dataList)):\n",
    "    sqDev = (dataList[i] - listMean)**2\n",
    "    SDAM += sqDev\n",
    "  SDCM = 0.0\n",
    "  for i in range(0,numClass):\n",
    "    if breaks[i] == 0:\n",
    "      classStart = 0\n",
    "    else:\n",
    "      classStart = dataList.index(breaks[i])\n",
    "      classStart += 1\n",
    "    classEnd = dataList.index(breaks[i+1])\n",
    "    classList = dataList[classStart:classEnd+1]\n",
    "    classMean = sum(classList)/len(classList)\n",
    "    print(classMean)\n",
    "    preSDCM = 0.0\n",
    "    for j in range(0,len(classList)):\n",
    "      sqDev2 = (classList[j] - classMean)**2\n",
    "      preSDCM += sqDev2\n",
    "    SDCM += preSDCM\n",
    "  return (SDAM - SDCM)/SDAM\n",
    "  \n",
    "# written by Drew\n",
    "# used after running getJenksBreaks()\n",
    "def classify(value, breaks):\n",
    "  for i in range(1, len(breaks)):\n",
    "    if value < breaks[i]:\n",
    "      return i\n",
    "  return len(breaks) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the pandas df object so that it can be sorted\n",
    "df_copy = dfj_tweet['TPP'].copy()\n",
    "# df_copy = pd.DataFrame(df_copy)\n",
    "# df_copy = df_copy[df_copy.TPP != 0]\n",
    "# getJenksBreaks(df_copy,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def htb(data):\n",
    "    \"\"\"\n",
    "    Function to compute the head/tail breaks algorithm on an array of data.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    data: python list\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    outp: python list - data representing a list of break points.\n",
    "    \"\"\"\n",
    "    # test input\n",
    "    assert len(data) > 0, \"Input must not be empty.\"\n",
    "    assert all(isinstance(_, int) or isinstance(_, float) for _ in data), \"All input values must be numeric.\"\n",
    "\n",
    "    outp = []  # array of break points\n",
    "\n",
    "    def htb_inner(data):\n",
    "        \"\"\"\n",
    "        Inner ht breaks function for recursively computing the break points.\n",
    "        \"\"\"\n",
    "        data_length = float(len(data))\n",
    "        data_mean = sum(data) / data_length\n",
    "        head = [_ for _ in data if _ > data_mean]\n",
    "        outp.append(data_mean)\n",
    "        while len(head) > 1 and len(head) / data_length < 0.40:\n",
    "            return htb_inner(head)\n",
    "    htb_inner(data)\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.293113487638042,\n 595.24724450583631,\n 4817.4680720601837,\n 27597.657811487581]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htb(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1-5', '5-25', '25-100', '>100']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybin.fenceposts = [0,1,5,25,100,50000]\n",
    "# mybin.fenceposts = [0, 1, 5, 30, 600, 5000, 50000]\n",
    "# np.linspace(np.log10(min(hist_data)), np.log10(max(hist_data)), 50)\n",
    "\n",
    "mybin.recalc(False)\n",
    "mybin.labels = ['0', '1-5', '5-25', '25-100', '>100']\n",
    "mybin.labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿name          County name, e.g. \"Santa Barbara\"\nstate         2-letter state abbreviation, e.g. CA\nmap_path      SVG path for county outline\nfips          Federal Information Processing Standards code for county in string format, e.g. \"06083\"\nfips_integer  Federal Information Processing Standards code for county in integer format, e.g. 6083\nmiddle_x      horizontal coordinate of center of county; not used for anything in this script, but provided just in case it's useful\nmiddle_y      vertical coordinate of center of county; not used for anything in this script, but provided just in case it's useful\n\n"
     ]
    }
   ],
   "source": [
    "with open('usa_counties_column_descriptions.txt', 'r', encoding='utf-8') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg = Chorogrid('usa_counties.csv', dfj_tweet.fips, mybin.colors_out, 'fips_integer')\n",
    "cg.set_title('Dam Nation: Social Listening in a Time of Crisis', font_dict={'font-size': 19})\n",
    "cg.set_legend(mybin.colors_in, mybin.labels, title='Tweets per resident * 100k')\n",
    "cg.draw_map(spacing_dict={'legend_offset':[-300,-200], 'margin_top': 50}) # otherwise legend will be cut off\n",
    "cg.done(show=True, save_filename='tweet_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('usa_counties_statelines.txt', 'r') as f:\n",
    "    statelines = f.read()\n",
    "cg.add_svg(statelines)\n",
    "cg.done(show=True, save_filename='tweet_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}